# Generating the tx2gene
library(GenomicFeatures)
#You have to set the working dyrectory to where the code is at
txdb <- makeTxDbFromGFF("../Data/hg19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf")
keytypes(txdb)
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- select(txdb, k, "GENEID", "TXNAME")
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/jonan/Documents/Tyseq/Code/") #All file locations will have a relative directionality in the file tree.
# Creating a sample table that maps each sample to its corresponding quant.sf file
sample_table <- data.frame(
sampleName = c("XIN460_C", "XGM061_C", "XJL334_C", "ZCA126_C", "XGZ492_C",
"AAFS251_D", "AAJ2482_D", "AABW178_D", "XIX456_D", "ABDG032_D"),
fileName = c(control_files, T1D_files),
diabetes_status = c(rep("No", 5), rep("Yes", 5))
)
# Setting up files for upload
# "../Data/SalmonQuant/quantALL/"
control_files = c("../Data/SalmonQuant/quantALL/1_XIN460_NHI_ATTACT_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/2_XGM061_NHI_TCCGGA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/3_XJL334_NHI_CGCTCA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/4_ZCA126_NHI_GAGATT_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/5_XGZ492_NHI_ATTCAG_L005_R1_001_quant.sf")
T1D_files = c("../Data/SalmonQuant/quantALL/6_AAFS251_T2DHI_GAATTC_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/7_AAJ2482_T2DHI_CTGAAG_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/8_AABW178_T2DHI_TAATGC_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/9_XIX456_T2DHI_CGGCTA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/10_ABDG032_T2DHI_TCCGCG_L005_R1_001_quant.sf")
# Creating a sample table that maps each sample to its corresponding quant.sf file
sample_table <- data.frame(
sampleName = c("XIN460_C", "XGM061_C", "XJL334_C", "ZCA126_C", "XGZ492_C",
"AAFS251_D", "AAJ2482_D", "AABW178_D", "XIX456_D", "ABDG032_D"),
fileName = c(control_files, T1D_files),
diabetes_status = c(rep("No", 5), rep("Yes", 5))
)
sample_table$diabetes_status
sample_table$diabetes_status[1]
sample_table$sampleName[1]
sample_table$sampleName[6]
sample_table$fileName[6]
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/jonan/Documents/Tyseq/Code/") #All file locations will have a relative directionality in the file tree.
library(tximport)
library(DESeq2)
txi <- tximport(files = sample_table$fileName, type = salmon, tx2gene = tx2gene)
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene)
# Generating the tx2gene
library(GenomicFeatures)
#You have to set the working directory to where the code is at
txdb <- makeTxDbFromGFF("../Data/hg19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf")
keytypes(txdb)
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- select(txdb, k, "TXNAME", "GENEID")
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- select(txdb, k, "TXNAME", "GENEID")
tx2gene <- select(txdb, k, "GENEID", "TXNAME")
tx2gene <- as.data.frame(tx2gene)
tx2gene <- tx2gene[, c("TXNAME", "GENEID")]
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene)
head(tx2gene)
head(tx2gene)
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene, ignoreTxVersion = TRUE)
quant <- read.delim("../Data/SalmonQuant/quantALL/1_XIN460_NHI_ATTACT_L005_R1_001_quant.sf", stringsAsFactors = FALSE)
head(quant)
if (is_present) {
print("Transcript ID is present in tx2gene mapping.")
} else {
print("Transcript ID is not found in tx2gene mapping.")
}
is_present <- transcript_id %in% tx2gene$TXNAME
if (is_present) {
print("Transcript ID is present in tx2gene mapping.")
} else {
print("Transcript ID is not found in tx2gene mapping.")
}
is_present <- transcript_id %in% tx2gene$TXNAME
transcript_id <- "ENST00000335137.3"
is_present <- transcript_id %in% tx2gene$TXNAME
if (is_present) {
print("Transcript ID is present in tx2gene mapping.")
} else {
print("Transcript ID is not found in tx2gene mapping.")
}
txi <- tximport(files = sample_table$fileName, type = "salmon")
txi <- tximport(files = sample_table$fileName, type = "salmon")
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene)
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene, ignoreAfterBar = TRUE)
txi
head(txi)
counts <- txi$counts
columnData <- data.frame(conditions = sample_table$diabetes_status)
dds <- DESeqDataSetFromMatrix(countData = counts, coldData = columnData, design = ~condition)
columnData
dds <- DESeqDataSetFromMatrix(countData = counts, coldData = columnData, design = ~condition)
counts
counts <- txi$counts
counts
counts <- txi$counts
counts
dds <- DESeqDataSetFromMatrix(countData = counts, coldData = columnData, design = ~condition) # ~condition is what tells it that I am interested in seeing the relationships based on condition
dds <- DESeqDataSetFromMatrix(countData = counts, colData = columnData, design = ~condition) # ~condition is what tells it that I am interested in seeing the relationships based on condition
counts <- round(txi$counts)
dds <- DESeqDataSetFromMatrix(countData = counts, colData = columnData, design = ~condition) # ~condition is what tells it that I am interested in seeing the relationships based on condition
dds <- DESeqDataSetFromMatrix(countData = counts, colData = columnData, design = ~diabetes_status) # ~condition is what tells it that I am interested in seeing the relationships based on condition
columnData <- data.frame(condition = sample_table$diabetes_status)
dds <- DESeqDataSetFromMatrix(countData = counts, colData = columnData, design = ~condition) # ~condition is what tells it that I am interested in seeing the relationships based on condition
dds
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/jonan/Documents/Tyseq/Code/") #All file locations will have a relative directionality in the file tree.
library(tximport) # Importing salmon files and preparing for deseq
library(DESeq2) # DGE Analysis
library(GenomicFeatures) # Generating the tx2gene
txdb <- makeTxDbFromGFF("../Data/hg19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf")
# keytypes(txdb)
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- select(txdb, k, "GENEID", "TXNAME")
tx2gene <- as.data.frame(tx2gene)
tx2gene <- tx2gene[, c("TXNAME", "GENEID")]
# Setting up files for upload
# "../Data/SalmonQuant/quantALL/"
control_files = c("../Data/SalmonQuant/quantALL/1_XIN460_NHI_ATTACT_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/2_XGM061_NHI_TCCGGA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/3_XJL334_NHI_CGCTCA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/4_ZCA126_NHI_GAGATT_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/5_XGZ492_NHI_ATTCAG_L005_R1_001_quant.sf")
T1D_files = c("../Data/SalmonQuant/quantALL/6_AAFS251_T2DHI_GAATTC_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/7_AAJ2482_T2DHI_CTGAAG_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/8_AABW178_T2DHI_TAATGC_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/9_XIX456_T2DHI_CGGCTA_L005_R1_001_quant.sf",
"../Data/SalmonQuant/quantALL/10_ABDG032_T2DHI_TCCGCG_L005_R1_001_quant.sf")
# Creating a sample table that maps each sample to its corresponding quant.sf file
# _C = control
# _D = Diabetic
sample_table <- data.frame(
sampleName = c("XIN460_C", "XGM061_C", "XJL334_C", "ZCA126_C", "XGZ492_C",
"AAFS251_D", "AAJ2482_D", "AABW178_D", "XIX456_D", "ABDG032_D"),
fileName = c(control_files, T1D_files),
diabetes_status = c(rep("No", 5), rep("Yes", 5))
)
txi <- tximport(files = sample_table$fileName, type = "salmon", tx2gene = tx2gene, ignoreAfterBar = TRUE)
counts <- round(txi$counts)
columnData <- data.frame(condition = sample_table$diabetes_status)
dds <- DESeqDataSetFromMatrix(countData = counts, colData = columnData, design = ~condition) # ~condition is what tells it that I am interested in seeing the relationships based on condition
#Adding the right column names to the dds object
colnames(dds) <- sample_table$sampleName
# colnames(dds)
# dds$condition - These should match with colnames(dds); they do.
# Checking to see that the right columns are associated to the right patient ID
# Get the column names from DESeq object
col_names = colnames(dds)
# Get the patient IDs from the sample table
patient_ids <- sample_table$sampleName
# Compare the column names with the sample name
# If match
match_result <- match(col_names, patient_ids)
match_result
# Print the results
for (i in seq_along(col_names)) {
cat("Column:", col_names[i], " - SampleName ID:", patient_ids[match_result[i]], "\n")
}
#Normalizing the counts
# Estimated size factors are determined by the library size
dds <- estimateSizeFactors(dds)
# dds$sizeFactor - Pretty cool to see the different relative sizer factors - Need to read about this
# Differential gene expression analysis
dds <- DESeq(dds)
# Getting the results based on the condition of diabetes or not
results <- results(dds, contrast = c("condition", "Yes", "No"))
top_genes <- results[order(results$padj), ]
top_10_genes <- head(top_genes, n=10)
top_10_genes
write.csv(top_10_genes, file = "../Data/to_10_genes.csv")
#Normalizing the counts
# Estimated size factors are determined by the library size
dds <- estimateSizeFactors(dds)
# dds$sizeFactor - Pretty cool to see the different relative sizer factors - Need to read about this
# Differential gene expression analysis
dds <- DESeq(dds)
# Getting the results based on the condition of diabetes or not
results <- results(dds, contrast = c("condition", "Yes", "No"))
top_genes <- results[order(results$padj), ]
top_30_genes <- head(top_genes, n=30)
top_30_genes
write.csv(top_30_genes, file = "../Data/top_30_genes_2.csv")
dfA = read.csv("../Data/top_30_genes.csv")
dfA = read.csv("../Data/top_30_genes_2.csv")
library(dplyr)
# Find values in dfA that are not present in dfB
values_only_in_dfA <- anti_join(dfA, dfB, by = "EnsembleID")
dfA = read.csv("../Data/top_30_genes.csv")
dfB = read.csv("../Data/top_30_genes_2.csv")
# Find values in dfA that are not present in dfB
values_only_in_dfA <- anti_join(dfA, dfB, by = "EnsembleID")
dfB = read.csv("../Data/top_30_genes_2.csv")
# Find values in dfA that are not present in dfB
values_only_in_dfA <- anti_join(dfA, dfB, by = "EnsembleID")
# Find values in dfB that are not present in dfA
values_only_in_dfB <- anti_join(dfB, dfA, by = "EnsembleID")
values_only_in_dfA
values_only_in_dfB
values_only_in_dfA
values_only_in_dfA
values_only_in_dfB
library(ggplot2)
# Calculate the negative log10 of the adjusted p-values
results$neg_log10_padj <- -log10(results$padj)
# Create a volcano plot
ggplot(results, aes(x = log2FoldChange, y = neg_log10_padj)) +
geom_point(color = "grey", alpha = 0.6) +
geom_point(data = subset(results, padj < 0.05 & abs(log2FoldChange) > 1),
color = "red", alpha = 0.6) +
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +
labs(x = "log2 Fold Change", y = "-log10(adjusted p-value)",
title = "Volcano Plot") +
theme_bw()
library(ggplot2)
# Assuming you have the DESeq results stored in the variable 'results'
# Convert DESeqResults object to data frame
results_df <- as.data.frame(results)
# Calculate the negative log10 of the adjusted p-values
results_df$neg_log10_padj <- -log10(results_df$padj)
# Create a volcano plot
ggplot(results_df, aes(x = log2FoldChange, y = neg_log10_padj)) +
geom_point(color = "grey", alpha = 0.6) +
geom_point(data = subset(results_df, padj < 0.05 & abs(log2FoldChange) > 1),
color = "red", alpha = 0.6) +
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +
labs(x = "log2 Fold Change", y = "-log10(adjusted p-value)",
title = "Volcano Plot") +
theme_bw()
library(ggplot2)
# Assuming you have a data frame called 'results' containing differential expression results
# with columns 'EnsembleID', 'log2FoldChange', and 'padj'
# Create the volcano plot
volcano_plot <- ggplot(results, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results$log2FoldChange)), max(abs(results$log2FoldChange)))) +
ylim(c(0, max(-log10(results$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +  # Adjust significance threshold
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +  # Adjust fold change threshold
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
# Assuming you have a data frame called 'results' containing differential expression results
# with columns 'EnsembleID', 'log2FoldChange', and 'padj'
# Convert DESeqResults object to data frame
results_df <- as.data.frame(results)
# Calculate the negative log10 of the adjusted p-values
results_df$neg_log10_padj <- -log10(results_df$padj)
# Create the volcano plot
volcano_plot <- ggplot(results, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results$log2FoldChange)), max(abs(results$log2FoldChange)))) +
ylim(c(0, max(-log10(results$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +  # Adjust significance threshold
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +  # Adjust fold change threshold
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
# Create the volcano plot
volcano_plot <- ggplot(results_df, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results$log2FoldChange)), max(abs(results$log2FoldChange)))) +
ylim(c(0, max(-log10(results$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +  # Adjust significance threshold
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +  # Adjust fold change threshold
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
# Add labels to significantly differentially expressed genes
signif_labels <- subset(results, padj < 0.05)  # Adjust significance threshold
volcano_plot_with_labels <- volcano_plot +
geom_text(data = signif_labels, aes(label = EnsembleID), vjust = 0, hjust = 0)
# Convert DESeqResults to a data frame
results <- as.data.frame(deseq_results)
# Create the volcano plot
volcano_plot <- ggplot(results, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results$log2FoldChange)), max(abs(results$log2FoldChange)))) +
ylim(c(0, max(-log10(results$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
library(ggplot2)
# Assuming you have a DESeqResults object called 'deseq_results'
# Convert DESeqResults to a data frame
results_df <- as.data.frame(results)
# Create the volcano plot
volcano_plot <- ggplot(results_df, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results_df$log2FoldChange)), max(abs(results_df$log2FoldChange)))) +
ylim(c(0, max(-log10(results_df$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
# Add labels to significantly differentially expressed genes
signif_labels <- subset(results_df, padj < 0.05)
volcano_plot_with_labels <- volcano_plot +
geom_text(data = signif_labels, aes(label = EnsembleID), vjust = 0, hjust = 0)
# Print the volcano plot with labels
print(volcano_plot_with_labels)
signif_labels
results_df$EnsembleID <- rownames(results_df)
# Create the volcano plot
volcano_plot <- ggplot(results_df, aes(x = log2FoldChange, y = -log10(padj))) +
geom_point() +
xlim(c(-max(abs(results_df$log2FoldChange)), max(abs(results_df$log2FoldChange)))) +
ylim(c(0, max(-log10(results_df$padj)))) +
geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue") +
geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "blue") +
xlab("log2 Fold Change") +
ylab("-log10(adjusted p-value)") +
ggtitle("Volcano Plot")
# Add labels to significantly differentially expressed genes
signif_labels <- subset(results_df, padj < 0.05)
volcano_plot_with_labels <- volcano_plot +
geom_text(data = signif_labels, aes(label = EnsembleID), vjust = 0, hjust = 0)
# Print the volcano plot with labels
print(volcano_plot_with_labels)
knitr::opts_chunk$set(echo = TRUE)
```{r}
BaselineAnalysis <- function(subid, dateof, ST){
#Inputs to Function:
#ID of participant
#Date of experiment (**Issue- would like to update so it pulls this from file)
#Participant skin tone (**Issue- would like to update so it pulls this from file)
#Outputs to Function:
#.csv file with all timestamps for every participant in the study, which has all devices used in the study, skin tone, activity condition, and participant ID
#Set filepath of folder with all subject data
filepath = sprintf("filepath\\%s", subid) #<- make sure to keep %s after filepath!
library(dplyr)
#Set filepath to file with all timestamps from study
timedata <- read.csv("filepath\\skintonestudyTIMES.csv", header=TRUE, stringsAsFactors = FALSE)
#If you get an error when running the following line, please re-install dplyr and re-start your R environment
idtime <- filter(timedata, timedata$?..Subject.ID==subid)
idtime <- filter(timedata, timedata$..Subject.ID==subid)
BaselineAnalysis <- function(subid, dateof, ST){
#Inputs to Function:
#ID of participant
#Date of experiment (**Issue- would like to update so it pulls this from file)
#Participant skin tone (**Issue- would like to update so it pulls this from file)
#Outputs to Function:
#.csv file with all timestamps for every participant in the study, which has all devices used in the study, skin tone, activity condition, and participant ID
#Set filepath of folder with all subject data
filepath = sprintf("filepath\\%s", subid) #<- make sure to keep %s after filepath!
library(dplyr)
#Set filepath to file with all timestamps from study
timedata <- read.csv("filepath\\skintonestudyTIMES.csv", header=TRUE, stringsAsFactors = FALSE)
#If you get an error when running the following line, please re-install dplyr and re-start your R environment
idtime <- filter(timedata, timedata$..Subject.ID==subid)
Times <- data.frame(matrix())
#REST
Times$R1 <- as.numeric(strptime(as.character(idtime$Baseline.Start.1), format='%m/%d/%Y %H:%M:%S'))
Times$R2 <- as.numeric(strptime(as.character(idtime$Baseline.Start.2), format='%m/%d/%Y %H:%M:%S'))
Times$R3 <- as.numeric(strptime(as.character(idtime$Baseline.Start.3), format='%m/%d/%Y %H:%M:%S'))
#ACTIVITY
Times$A1 <- as.numeric(strptime(as.character(idtime$Activity.Start.1), format='%m/%d/%Y %H:%M:%S'))
Times$A2 <- as.numeric(strptime(as.character(idtime$Activity.Start.2), format='%m/%d/%Y %H:%M:%S'))
Times$A3 <- as.numeric(strptime(as.character(idtime$Activity.Start.3), format='%m/%d/%Y %H:%M:%S'))
#DEEP BREATHING
Times$B1 <- as.numeric(strptime(as.character(idtime$DB.Start.1), format='%m/%d/%Y %H:%M:%S'))
Times$B2 <- as.numeric(strptime(as.character(idtime$DB.Start.2), format='%m/%d/%Y %H:%M:%S'))
Times$B3 <- as.numeric(strptime(as.character(idtime$DB.Start.3), format='%m/%d/%Y %H:%M:%S'))
#TYPEING
Times$T1 <- as.numeric(strptime(as.character(idtime$Type.Start.1), format='%m/%d/%Y %H:%M:%S'))
Times$T2 <- as.numeric(strptime(as.character(idtime$Type.Start.2), format='%m/%d/%Y %H:%M:%S'))
Times$T3 <- as.numeric(strptime(as.character(idtime$Type.Start.3), format='%m/%d/%Y %H:%M:%S'))
Times$R1 = as.POSIXct(round(as.numeric(Times$R1)), origin = "1970-01-01")
Times$R2 = as.POSIXct(round(as.numeric(Times$R2)), origin = "1970-01-01")
Times$R3 = as.POSIXct(round(as.numeric(Times$R3)), origin = "1970-01-01")
Times$A1 = as.POSIXct(round(as.numeric(Times$A1)), origin = "1970-01-01")
Times$A2 = as.POSIXct(round(as.numeric(Times$A2)), origin = "1970-01-01")
Times$A3 = as.POSIXct(round(as.numeric(Times$A3)), origin = "1970-01-01")
Times$B1 = as.POSIXct(round(as.numeric(Times$B1)), origin = "1970-01-01")
Times$B2 = as.POSIXct(round(as.numeric(Times$B2)), origin = "1970-01-01")
Times$B3 = as.POSIXct(round(as.numeric(Times$B3)), origin = "1970-01-01")
Times$T1 = as.POSIXct(round(as.numeric(Times$T1)), origin = "1970-01-01")
Times$T2 = as.POSIXct(round(as.numeric(Times$T2)), origin = "1970-01-01")
Times$T3 = as.POSIXct(round(as.numeric(Times$T3)), origin = "1970-01-01")
#Import ECG HR
mydate = strptime(dateof,format='%Y-%m-%d')
datenum <- as.numeric(mydate)
#Import HR data from Kubios
HR <- read.csv(sprintf("%s\\HR.csv", filepath), header=FALSE)
HRT <- read.csv(sprintf("%s\\HRT.csv", filepath), header=FALSE)
HRT <- round((HRT)+datenum)
ECG <- data.frame(HRT, HR)
colnames(ECG) <- c("Time", "ECG")
ECG$Time = as.POSIXct(round(as.numeric(ECG$Time)), origin = "1970-01-01")
#IMPORT Empatica HR
E4 <- read.csv(sprintf("%s\\Empatica\\HR.csv", filepath), header=FALSE, stringsAsFactors=FALSE)
E4starttime <- E4[1,]
E4 <- E4[-c(1,2), ]
secondspassedE4 <- length(E4)/1
E4endtime <- E4starttime + secondspassedE4
E4Time <- as.numeric(seq(from=E4starttime, to=E4endtime, length.out=length(E4)))
E4 <- data.frame(E4Time, E4)
colnames(E4) <- c("Time", "Empatica")
E4$Time = as.POSIXct(round(as.numeric(E4$Time)), origin = "1970-01-01")
rm(E4starttime, secondspassedE4, E4endtime, E4Time)
#IMPORT Apple Watch HR
AW <- read.csv(sprintf("%s\\Apple Watch.csv", filepath), header=FALSE, stringsAsFactors=FALSE)
AWstarttime <- AW[1,2]
AWstarttime <- as.numeric(as.POSIXct(AWstarttime))
AppleHR <- as.numeric(AW[-c(1:7),2])
Applesec <- as.numeric(AW[-c(1:7),1])+AWstarttime
AppleWatch <- data.frame(Applesec, AppleHR)
colnames(AppleWatch) <- c("Time", "AppleWatch")
AppleWatch$Time = as.POSIXct(round(as.numeric(AppleWatch$Time)), origin = "1970-01-01")
rm(AW, AWstarttime, AppleHR, Applesec)
#IMPORT Fitbit HR
FB <- read.csv(sprintf("%s\\Fitbit.csv", filepath), header=FALSE, stringsAsFactors = FALSE)
FBHR <- as.numeric(FB[-c(1), 2])
FBtime <- FB[-c(1),1]
Date <- rep(as.POSIXct(dateof), length(FBtime))
FBdt <- paste(Date, FBtime)
FBdt <- as.numeric(as.POSIXct(FBdt, format="%Y-%m-%d %H:%M:%S"))
Fitbit <- data.frame(FBdt, FBHR)
colnames(Fitbit) <- c("Time", "Fitbit")
Fitbit$Time = as.POSIXct(round(as.numeric(Fitbit$Time)), origin = "1970-01-01")
rm(FB, FBHR, FBtime, Date, FBdt)
#IMPORT Garmin HR
require(XML)
require(reshape)
library(parsedate)
if(file.exists(sprintf("%s\\garmin.tcx", filepath))){
mapData <- xmlParse(sprintf("%s\\garmin.tcx", filepath))
#Import raw TCX to dataframe. This will be used to generate map data
GM <- xmlToDataFrame(nodes <- getNodeSet(mapData, "//ns:Trackpoint", "ns"))
GMtime <- unlist(GM$Time)
garmint <- as.numeric(parse_date(GMtime))
garminhr <- as.numeric(as.matrix(GM$HeartRateBpm))
Garmin <- data.frame(garmint, garminhr)
rm(mapData, GM, GMtime, garmint, garminhr, nodes)
} else {
garmint <- NA
garminhr <- NA
Garmin <- data.frame(garmint, garminhr)}
colnames(Garmin) <- c("Time", "Garmin")
Garmin$Time = as.POSIXct(round(as.numeric(Garmin$Time)), origin = "1970-01-01")
#IMPORT Miband HR
library("readxl")
if(file.exists(sprintf("%s\\Miband.xls", filepath))){
MB <- read_excel(sprintf("%s\\Miband.xls", filepath))
MBHR <- MB[1]
MBtime <- MB[2]/1000
options(scipen = 1)
Miband <- data.frame(MBtime, MBHR)
rm(MB, MBHR, MBtime)
} else {
Heart.rate <- NA
Timestamp <- NA
Miband <- data.frame(Timestamp, Heart.rate)}
colnames(Miband) <- c("Time", "Miband")
Miband$Time = as.POSIXct(round(as.numeric(Miband$Time)), origin = "1970-01-01")
#IMPORT Biovotion HR
if(file.exists(sprintf("%s\\Biovotion\\BHR.csv", filepath))){
BV <- read.csv(sprintf("%s\\Biovotion\\BHR.csv", filepath), header=TRUE, stringsAsFactors = FALSE)
Time <- BV$Timestamp
HR <- BV$Value
Biovotion <- data.frame(Time, HR)
rm(BV, Time, HR)
} else {
Time <- NA
HR <- NA
Biovotion <- data.frame(Time, HR)}
colnames(Biovotion) <- c("Time", "Biovotion")
Biovotion$Time = as.POSIXct(round(as.numeric(Biovotion$Time)), origin = "1970-01-01")
#Merge all data by timestamps. Keep all timestamps.
r1 <-merge(ECG, AppleWatch, all=T)
r2 <-merge(r1, E4, by="Time", all=T)
r3 <-merge(r2, Garmin, by="Time", all=T)
r4 <-merge(r3, Fitbit, by="Time", all=T)
r5 <-merge(r4, Miband, by="Time", all=T)
result <-merge(r5, Biovotion, by="Time", all=T)
rm(r1, r2, r3, r4, r5)
result$ID <- subid
result$ST <- ST
#Define Condition as Rest, Activity (Walking), Breathe (Deep Breathing), and Typeing (Type)
result$Condition[between(result$Time,Times$A1,Times$A1+300)] <- "Activity"
result$Condition[between(result$Time,Times$A2,Times$A2+300)] <- "Activity"
result$Condition[between(result$Time,Times$A3,Times$A3+300)] <- "Activity"
result$Condition[between(result$Time,Times$R1,Times$R1+240)] <- "Rest"
result$Condition[between(result$Time,Times$R2,Times$R2+240)] <- "Rest"
result$Condition[between(result$Time,Times$R3,Times$R3+240)] <- "Rest"
result$Condition[between(result$Time,Times$B1,Times$B1+60)] <- "Breathe"
result$Condition[between(result$Time,Times$B2,Times$B2+60)] <- "Breathe"
result$Condition[between(result$Time,Times$B3,Times$B3+60)] <- "Breathe"
result$Condition[between(result$Time,Times$T1,Times$T1+60)] <- "Type"
result$Condition[between(result$Time,Times$T2,Times$T2+60)] <- "Type"
result$Condition[between(result$Time,Times$T3,Times$T3+60)] <- "Type"
# Write to large .csv that contains all data for all participants
write.table(result, file = "filename.csv", sep = ",", append = TRUE, quote = FALSE, col.names = FALSE, row.names = FALSE)
}
#Run function for all participants:
BaselineAnalysis('19-###', '2019-##-##', #)
#Run function for all participants:
BaselineAnalysis('19-###', '2019-##-##', )
#Run function for all participants:
BaselineAnalysis('19-###', '2019-##-##', )
filepath = sprintf("filepath\\%s", subid) #<- make sure to keep %s after filepath!
filepath = sprintf("filepath\\%s", '19-###') #<- make sure to keep %s after filepath!
library(dplyr)
#Set filepath to file with all timestamps from study
timedata <- read.csv("filepath\\skintonestudyTIMES.csv", header=TRUE, stringsAsFactors = FALSE)
filepath
